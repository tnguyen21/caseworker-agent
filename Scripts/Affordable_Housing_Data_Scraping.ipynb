{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "q08ozpdFRWXH",
        "outputId": "852c697c-482a-4484-ab2c-284e9b9d8ce6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.11/dist-packages (4.29.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (2.3.0)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.29.0)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.12.2)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (2025.1.31)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.11/dist-packages (from selenium) (4.12.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (25.1.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (3.10)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.11/dist-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:2 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,956 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,533 kB]\n",
            "Fetched 4,756 kB in 3s (1,809 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "chromium-browser is already the newest version (1:85.0.4183.83-0ubuntu2.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 32 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "chromium-chromedriver is already the newest version (1:85.0.4183.83-0ubuntu2.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 32 not upgraded.\n",
            "/usr/lib/chromium-browser/chromedriver\n"
          ]
        }
      ],
      "source": [
        "#Installing Selenium and chrome driver\n",
        "!pip install selenium\n",
        "!apt-get update\n",
        "!apt-get install -y chromium-browser\n",
        "!apt install chromium-chromedriver\n",
        "\n",
        "#Setting up a Chrome browser that can be used to automate web interactions, such as clicking buttons, filling forms, and scraping data from websites.\n",
        "def web_driver():\n",
        "    options = webdriver.ChromeOptions()\n",
        "    options.add_argument(\"--verbose\")\n",
        "    options.add_argument('--no-sandbox')\n",
        "    options.add_argument('--headless')\n",
        "    options.add_argument('--disable-gpu')\n",
        "    options.add_argument(\"--window-size=1920, 1200\")\n",
        "    options.add_argument('--disable-dev-shm-usage')\n",
        "    driver = webdriver.Chrome(options=options)\n",
        "    return driver\n",
        "\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.common.exceptions import TimeoutException, ElementClickInterceptedException, NoSuchElementException\n",
        "import time\n",
        "import csv\n",
        "\n",
        "!ls /usr/lib/chromium-browser/chromedriver"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The main code for scraping and aquiring the listings from www.forsalebyowner.com\n",
        "driver = web_driver()\n",
        "\n",
        "#url\n",
        "driver.get('https://www.affordablehousing.com/philadelphia-pa/')\n",
        "\n",
        "# Wait for the page to load\n",
        "time.sleep(5)\n",
        "\n",
        "scraped_results = []\n",
        "\n",
        "# Function to close modals (if any)\n",
        "def close_modals():\n",
        "    try:\n",
        "        modal_close_button = WebDriverWait(driver, 10).until(\n",
        "            EC.element_to_be_clickable((By.CLASS_NAME, \"modal--cls--btn fas fa-times closemodal\")))\n",
        "        modal_close_button.click()\n",
        "        print(\"Modal closed\")\n",
        "    except TimeoutException:\n",
        "        print(\"No modal or close button found\")\n",
        "\n",
        "# Function to click the \"Next\" button\n",
        "def click_view_more():\n",
        "    try:\n",
        "        view_more_button = WebDriverWait(driver, 10).until(\n",
        "            EC.element_to_be_clickable((By.XPATH, '//a[@data-bind=\"click: function () { GoToNext(); }\"]')))  #or //*[text()=\"Next\"]\n",
        "        view_more_button.click()\n",
        "        print(\"View More Listings button clicked\")\n",
        "        return True\n",
        "    except ElementClickInterceptedException:\n",
        "        print(\"Element click intercepted, trying to wait for modal to disappear\")\n",
        "        try:\n",
        "            WebDriverWait(driver, 10).until(\n",
        "                EC.invisibility_of_element_located((By.CLASS_NAME, \"modal--cls--btn fas fa-times closemodal\")))\n",
        "            view_more_button.click()\n",
        "            print(\"View More Listings button clicked after modal disappeared\")\n",
        "            return True\n",
        "        except TimeoutException:\n",
        "            print(\"Failed to wait for modal to disappear\")\n",
        "            return False\n",
        "    except TimeoutException:\n",
        "        print(\"View More Listings button not clickable\")\n",
        "        return False\n",
        "\n",
        "#Function to collect the data listing from website\n",
        "def extract_listings():\n",
        "    listings = []\n",
        "    try:\n",
        "        body = WebDriverWait(driver, 10).until(\n",
        "            EC.presence_of_element_located((By.XPATH, '//*[@id=\"divtnResultPage\"]')))\n",
        "\n",
        "        print(\"Body element found.\")\n",
        "\n",
        "        property_elements = body.find_elements(By.XPATH, '//div[contains(@class, \"tnresult--card\")]') #//*[@id=\"divtnResultList\"]/div[4]/div[2]/div[3]/div[2]\n",
        "\n",
        "        print(f\"Found {len(property_elements)} property elements.\")\n",
        "\n",
        "        if len(property_elements) == 0:\n",
        "            print(\"No property elements found. Please verify the XPath.\")\n",
        "\n",
        "        for idx, property_element in enumerate(property_elements):\n",
        "            try:\n",
        "                # Extract property title and location\n",
        "                #title = property_element.find_element(By.XPATH, './/a[contains(@class, \"block text-xl font-bold\")]').text\n",
        "                location = property_element.find_element(By.XPATH, './/div[contains(@class, \"tnresult--price\")]').text\n",
        "                # Extract price\n",
        "                price = property_element.find_element(By.XPATH, './/div[contains(@class, \"tnresult--propertyaddress\")]').text\n",
        "                # Extract property details (e.g., Beds, Baths, Acres)\n",
        "                #details = property_element.find_element(By.XPATH, '//*[@id=\"divtnResultList\"]/div[4]/div[2]/div[3]/div[3]/div[2]/div/div/div[2]').text\n",
        "                # Extract seller information (optional)\n",
        "                #property_type = property_element.find_element(By.XPATH, '//*[@id=\"0\"]/div[2]/ah-property-type/span').text\n",
        "\n",
        "                # Add the data to the listings list\n",
        "                listings.append({\n",
        "                   # \"Title\": title,\n",
        "                    \"Location\": location,\n",
        "                    \"Price\": price,\n",
        "                    #\"Details\": details,\n",
        "                    #\"Property Type\": property_type,\n",
        "                })\n",
        "            except NoSuchElementException as e:\n",
        "                # If an element is missing, let's print the HTML of the property element to debug\n",
        "                print(f\"Error for property {idx + 1}: {e}\")\n",
        "                #print(\"Property HTML: \", property_element.get_attribute('outerHTML'))\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting listings: {e}\")\n",
        "    return listings\n",
        "\n",
        "# Function to save the data to a CSV file\n",
        "def save_to_csv(listings, filename=\"Housing.csv\"):\n",
        "    keys = listings[0].keys()\n",
        "    with open(filename, mode='w', newline='', encoding='utf-8') as file:\n",
        "        writer = csv.DictWriter(file, fieldnames=keys)\n",
        "        writer.writeheader()\n",
        "        for listing in listings:\n",
        "            writer.writerow(listing)\n",
        "    print(f\"Data saved to {filename}\")\n",
        "\n",
        "\n",
        "# Main function to scrape all listings (including \"View More Listings\")\n",
        "def scrape_all_listings(max_lookups=1500, target_listings=2500):\n",
        "    all_listings = []\n",
        "    last_listing_count = 0\n",
        "    lookup_count = 0\n",
        "\n",
        "    while True:\n",
        "        if lookup_count >= max_lookups:\n",
        "            print(\"Reached maximum lookup count. Stopping.\")\n",
        "            break\n",
        "\n",
        "        listings = extract_listings()\n",
        "\n",
        "        # Check if there are any new listings\n",
        "        if len(listings) == 0:\n",
        "            print(\"No new listings found.\")\n",
        "            break\n",
        "\n",
        "        # Append unique listings only (check for duplicates based on a unique key, e.g., title + location)\n",
        "        for listing in listings:\n",
        "            if listing not in all_listings:\n",
        "                all_listings.append(listing)\n",
        "\n",
        "        print(f\"Total listings found so far: {len(all_listings)}\")\n",
        "\n",
        "        # Stop if we have reached the target number of listings\n",
        "        if len(all_listings) >= target_listings:\n",
        "            print(f\"Reached the target number of {target_listings} listings. Stopping.\")\n",
        "            break\n",
        "\n",
        "        # Check if the number of listings has increased, if not, break the loop\n",
        "        if len(all_listings) == last_listing_count:\n",
        "            print(\"No new listings found. Ending the scraping process.\")\n",
        "            break\n",
        "\n",
        "        last_listing_count = len(all_listings)\n",
        "\n",
        "        # Try to load more listings\n",
        "        more_loaded = click_view_more()\n",
        "        if not more_loaded:\n",
        "            print(\"No more listings to load.\")\n",
        "            break\n",
        "\n",
        "        lookup_count += 1\n",
        "        time.sleep(10)  # Add a delay to reduce the load on the website\n",
        "\n",
        "    return all_listings\n",
        "\n",
        "\n",
        "# Run the scraping process\n",
        "try:\n",
        "    all_listings = scrape_all_listings()\n",
        "    print(f\"Scraping complete. Found {len(all_listings)} listings.\")\n",
        "\n",
        "    if all_listings:\n",
        "        save_to_csv(all_listings)\n",
        "\n",
        "    for listing in all_listings:\n",
        "        print(listing)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "\n",
        "finally:\n",
        "    driver.quit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwSthOLKbyJZ",
        "outputId": "1d4474ea-e004-4b13-de47-e09939647ec9",
        "collapsed": true
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Body element found.\n",
            "Found 64 property elements.\n",
            "Total listings found so far: 31\n",
            "View More Listings button not clickable\n",
            "No more listings to load.\n",
            "Scraping complete. Found 31 listings.\n",
            "Data saved to Housing.csv\n",
            "{'Location': '$1,780', 'Price': '1033 S 55th St, 1st Flr, Philadelphia, PA 19143'}\n",
            "{'Location': '$1,780', 'Price': '1122 Marlyn Rd, Philadelphia, PA 19151'}\n",
            "{'Location': '$1,300', 'Price': '4509 Laird St, Philadelphia, PA 19139'}\n",
            "{'Location': '$945', 'Price': '5813 Willows Ave, 3-R, Philadelphia, PA 19143'}\n",
            "{'Location': '$1,675', 'Price': '5816 Pemberton St, Philadelphia, PA 19143'}\n",
            "{'Location': '$1,500', 'Price': '5844 Pentridge St, Philadelphia, PA 19143'}\n",
            "{'Location': '$1,700', 'Price': '6101 Tackawanna St, 2, Philadelphia, PA 19135'}\n",
            "{'Location': '$1,800', 'Price': '852 N 41st St, 1, Philadelphia, PA 19104'}\n",
            "{'Location': '$1,750', 'Price': '6230 Delancey St, 0, Philadelphia, PA 19143'}\n",
            "{'Location': '$1,600', 'Price': '1226 W Oakdale St, Philadelphia, PA 19133'}\n",
            "{'Location': '$1,000', 'Price': '4208 W Thompson St, Philadelphia, PA 19104'}\n",
            "{'Location': '$1,850', 'Price': '1522 W Girard Ave, Philadelphia, PA 19130'}\n",
            "{'Location': '$1,550', 'Price': '1127 W Cumberland St, 1A, Philadelphia, PA 19133'}\n",
            "{'Location': '$1,500', 'Price': '4507 N Uber St, 2, Philadelphia, PA 19140'}\n",
            "{'Location': '$1,995', 'Price': '5008 Keyser St, Philadelphia, PA 19144'}\n",
            "{'Location': '$1,480', 'Price': '3334 N Hope St, Philadelphia, PA 19140'}\n",
            "{'Location': '$1,925', 'Price': '4704 Blakiston St, Philadelphia, PA 19136'}\n",
            "{'Location': '$1,400', 'Price': '2352 N Colorado St, Philadelphia, PA 19132'}\n",
            "{'Location': '$1,500', 'Price': '1415 N Hobart St, Philadelphia, PA 19131'}\n",
            "{'Location': '$1,195', 'Price': '5813 Willows Ave, 3F, Philadelphia, PA 19143'}\n",
            "{'Location': '$1,750', 'Price': '1843 N 25th St, Philadelphia, PA 19121'}\n",
            "{'Location': '$1,500', 'Price': '938 N 66th St, 2, Philadelphia, PA 19151'}\n",
            "{'Location': '$1,600', 'Price': '3235 N 27th St, Philadelphia, PA 19129'}\n",
            "{'Location': '$1,500', 'Price': '4842 Westminster Ave, Philadelphia, PA 19131'}\n",
            "{'Location': '$1,375', 'Price': '1336 S Wilton St, Philadelphia, PA 19143'}\n",
            "{'Location': '$1,600', 'Price': '3856 Olive St, Philadelphia, PA 19104'}\n",
            "{'Location': '$1,475', 'Price': '4860 N 8th St, Ground, Philadelphia, PA 19120'}\n",
            "{'Location': '$2,000', 'Price': '1942 N 32nd St, Philadelphia, PA 19121'}\n",
            "{'Location': '$1,480', 'Price': '3808 Archer St, Philadelphia, PA 19140'}\n",
            "{'Location': '$901-$1,047', 'Price': '1336 Arrott St, C12, Philadelphia, PA 19124'}\n",
            "{'Location': '$1,913', 'Price': '2248 E Somerset St, 3, Philadelphia, PA 19134'}\n"
          ]
        }
      ]
    }
  ]
}